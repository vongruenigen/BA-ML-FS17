\chapter{Using the Software System}
\label{appendix:software_usage}
The following chapter gives a tutorial on how to use the software system (see Chapter~\ref{software_system}) implemented to conduct the experiments in this thesis.

\section{Download}
The code of the software system can be downloaded by using \texttt{git}\footnote{https://git-scm.com/}. The repository is located in the publicly accessible GitHub server of the ZHAW\footnote{https://github.ch/vongrdir/BA-ML-17}.

\section{Requirements}
To use the software and all the related scripts, the following software packages must be installed:

\begin{itemize}[noitemsep]
	\item \texttt{python} in the version 3.4.3\footnote{https://www.python.org/}
	\item If a GPU is used:
	\begin{itemize}[noitemsep]
		\item Nvidia GPU driver\footnote{http://www.nvidia.de/Download/index.aspx} for the respective GPU.
		\item Nvidia \texttt{cuda} 8 toolkit\footnote{https://developer.nvidia.com/cuda-toolkit}.
	\end{itemize}
\end{itemize}

The experiments and script can also be conducted without a GPU and solely on the CPU. However, this leads to higher runtime in several parts of the system, mainly when training models. In addition to the mentioned software packages the following \texttt{python} libraries must be installed:

\begin{itemize}[noitemsep]
	\item \texttt{numpy} Version 1.11.1
	\item \texttt{theano} Version 0.8.2
	\item \texttt{keras} Version 1.1.0
	\item \texttt{nltk} Version 3.2.1
	\item \texttt{scikit{\_}learn} Version 0.18
	\item \texttt{matplotlib} Version 1.5.3
	\item \texttt{gensim} Version 0.12.4
	\item \texttt{h5py} Version 2.6.0
	\item \texttt{flask} Version 0.11.1
\end{itemize}
\todo{update}

The libraries can be installed via the \texttt{python} package manager \texttt{pip}\footnote{https://packaging.python.org/installing/}. It is recommended to us the exact versions of the mentioned software packages and \texttt{python} libraries to avoid any compatibility issues. However, it might certainly be possible that the software system runs find with newer version without any problems.

\clearpage
\section{Structure of the Repository}
In the following table, we explain the structure of the repository and the contents of the main directories.

\begin{table}[H]
	\centering
	\begin{tabularx}{\textwidth}{lX}
		\toprule
		Name of Directory & Description\\ \midrule
		\texttt{configs/} & In this directory, all the JSONconfigurations for all experiments are stored.\\
		\texttt{report/} & All documents related to the thesis itself are stored in this directory.\\
		\texttt{results/} & The results of all the run experiments are stored in this directory. The results themselves are stored in a directory named after the \texttt{WHAT} of the experiment. In total, the model, all collected metrics and the configuration of experiments are stored in this directories.\\
		\texttt{scripts/} & The scripts used in this thesis are stored in this directory (see Chapter~\ref{sofware_usage:scripts}).\\
		\texttt{source/} & The whole source code of the software system itself is located in this directory including all the components necessary to implement the system described in the Chapter~\ref{sofware_system}.\\
		\bottomrule
	\end{tabularx}
	\caption{Remarks regarding the structure of the repository.}
\end{table}
\todo{update}

\clearpage
\section{Using the Scripts}
In the following section, we are going to introduce the most important scripts necessary to use the software system for running experiments. The scripts themselves are located in the directory \texttt{scripts/}.

\begin{table}[H]
	\centering
	\ra{1.3}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{lp{8cm}p{8cm}}
			\toprule
			Name & Description\\ \midrule
			\texttt{aggregate{\_}results{\_}metrics.py} & Mithilfe dieses Skripts können die Resultate eines oder mehrerer Experimente aggregiert werden. Diese werden dann in eine CSV Datei im aktuellen Arbeitsverzeichnis abgelegt.\\
			\texttt{extract{\_}embeddings.py} & Word-Embeddings, welche mit \texttt{word2vec} erstellt wurden, müssen ausgepackt werden bevor diese in den Experimenten verwendet werden können. Dieses Skript ist dafür zuständig.\\
			\texttt{extract{\_}embeddings{\_}glove.py} & Word-Embeddings, welche mit \texttt{glove} erstellt wurden, müssen ausgepackt werden bevor diese in den Experimenten verwendet werden können. Dieses Skript ist dafür zuständig.\\
			\texttt{extract{\_}embeddings{\_}vocabulary.py} & Das Vokabular von Word-Embeddings können mithilfe dieses Skripts extrahiert werden.\\
			\texttt{generate{\_}data{\_}statistics.py} & Mithilfe dieses Skripts können Statistiken ein oder mehrerer TSV Dateien erstellt werden. Dabei werden die darin enthaltenen Texte und Sentiments analysiert.\\
			\texttt{preprocess{\_}tsv{\_}data.py} & Mithilfe dieses Skripts können Daten aus einer TSV-Datei vorverarbeitet und im HDF5 Format abgespeichert werden. Dies ist nötig um z.B. die Daten für die Distant-Phasen vorzubereiten.\\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption{Descriptions of the most important scripts to use the software system.}
\end{table}
\todo{update}

There are much more scripts than ones described above (e.g. for plotting, creation of vocabularies). Especially. Not all of them are necessary to conduct experiments, which is why only explain the most important.

In the following table there are exemplary calls for all scripts listed above:

\begin{table}[H]
	\centering
	\ra{1.3}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{lp{20cm}}
			\toprule
			Name & Bespielaufruf\\ \midrule
			\texttt{aggregate{\_}results{\_}metrics.py} & python scripts/aggregate{\_}results{\_}metrics.py results/my-experiment-group/my-experiment\\
			\texttt{extract{\_}embeddings.py} & python scripts/extract{\_}embeddings.py -e embeddings/my-embeddings -v vocabularies/vocabulary.pickle -o embeddings/my-extracted-embeddings\\
			\texttt{extract{\_}embeddings{\_}glove.py} & python scripts/extract{\_}embeddings{\_}glove.py -e embeddings/my-glove-embeddings -v vocabularies/vocabulary.pickle -o embeddings/my-extracted-embeddings\\
			\texttt{extract{\_}embeddings{\_}vocabulary.py} & python scripts/extract{\_}embeddings{\_}vocabulary.py.py -e embeddings/my-glove-embeddings -v vocabularies/vocabulary.pickle -o embeddings/my-extracted-embeddings\\
			\texttt{generate{\_}data{\_}statistics.py} & python scripts/generate{\_}data{\_}statistics.py testdata/my-data.tsv\\
			\texttt{preprocess{\_}tsv{\_}data.py} & python scripts/preprocess{\_}tsv{\_}data.py -t my-data.tsv -o preprocessed.h5 -s 140 -v vocabularies/my-vocabulary.pickle -m 1000000\\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption{Exemplary calls for the most important scripts to use the software system.}
\end{table}
\todo{update}

\clearpage

\section{Running Experiments}
To run experiments, one has to write a configuration file in the JSON format. All of them reside in the directory \texttt{configs/}. In the following table, all important configuration parameters are explained:

\begin{table}[H]
	\centering
	\ra{1.3}
	\begin{adjustbox}{max width=\textwidth, max height=\textheight}
		\begin{tabular}{llp{10cm}}
			\toprule
			Name & Default Value & Description\\ \midrule
			\texttt{batch{\_}size} & \texttt{500} & Mithilfe dieses Parameters kann konfiguriert werden mit welcher Batch-Size das Training des CNN durchgeführt wird.\\
			\texttt{early{\_}stopping{\_}monitor{\_}metric} & \texttt{val{\_}f1{\_}score{\_}pos{\_}neg} & Damit wird konfiguriert, welche Metrik durch das Early-Stopping überwacht werden soll.\\
			\texttt{early{\_}stopping{\_}patience} & \texttt{75} & Über diesen Parameter kann konfiguriert werden wieviel Epochen ohne Fortschritt bezüglich der \texttt{early{\_}stopping{\_}monitor{\_}metric} Metrik trainiert wird, bevor das Training abgebrochen wird.\\
			\texttt{max{\_}sent{\_}length} & \texttt{140} & Mithilfe dieses Parameters kann angegeben werden, wieviele Wörter pro Satz maximal erlaubt sind. Längere Sätze werden demnach gekürzt.\\
			\texttt{nb{\_}epoch} & \texttt{1000} & Dieser Parameter ist dafür zuständig, über wieviel Epochen hinweg das Training durchgeführt wird.\\
			\texttt{nb{\_}kfold{\_}cv} & \texttt{4} & Wenn dieser Parameter vorhanden ist, wird während des Trainings k-fold Cross-Validation verwendet. Bei einem Parameterwerte kleiner als $2$ wird keine k-fold Cross-Validation durchgeführt.\\
			\texttt{early{\_}stopping{\_}patience} & \texttt{75} & Über diesen Parameter kann konfiguriert werden wieviel Epochen ohne Fortschritt bezüglich der \texttt{early{\_}stopping{\_}monitor{\_}stopping} trainiert wird, bevor das Training abgebrochen wird.\\
			\texttt{name} & \texttt{null} & Muss gesetz werden, da das Experiment dem Namen entsprechend im \texttt{results/} Verzeichnis abgelegt wird.\\
			\texttt{group{\_}id} & \texttt{null} & Muss gesetzt werden, da Experimente nach diesem Namen im \texttt{results/} Verzeichnis gruppiert werden.\\
			\texttt{model{\_}json{\_}path} & \texttt{null} & Gibt den Pfad zur JSON Datei mit dem zu ladenden \texttt{keras} Modell an. Darf nur angegeben werden sofern auch ein Wert für \texttt{model{\_}weights{\_}path} gesetzt ist, sonst tritt beim Start ein Fehler auf.\\
			\texttt{model{\_}id} & \texttt{1} & Damit können verschiedene Versionen des verwendeten CNN geladen werden (z.B. unterschiedliche Anzahl Convolutional Schichten). Welche ID für welches Modell steht ist in der Datei \texttt{source/model.py} ersichtlich.\\
			\texttt{model{\_}weights{\_}path} & \texttt{null} & Gibt den Pfad zur HDF5 Datei mit den zu ladenden Gewichten an. Darf nur angegeben werden sofern auch ein Wert für \texttt{model{\_}json{\_}path} gesetzt ist.\\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption{Explanation of the important configuration parameters of the software system (part 1).}
\end{table}

\clearpage

\begin{table}[H]
	\centering
	\ra{1.3}
	\begin{adjustbox}{max width=\textwidth, max height=\textheight}
		\begin{tabular}{llp{10cm}}
			\toprule
			Name & Default Value & Description\\ \midrule
			\texttt{monitor{\_}metric} & \texttt{val{\_}f1{\_}score{\_}pos{\_}neg} & Mithilfe dieses Parameters kann konfiguriert werden, welche Metrik ausschlaggebend ist um am Ende des Trainings zu entscheiden, welcher der beste Fold war. Wird nur beachtet wenn k-fold Cross-Validation aktiviert ist.\\
			\texttt{monitor{\_}metric{\_}mode} & \texttt{max} & Mithilfe dieses Parameter wird konfiguriert ob die \texttt{monitor{\_}metric} nach dem maximalen oder minimalen Wert überwacht werden soll.\\
			\texttt{preprocessed{\_}data} & \texttt{null} & Hier kann die HDF5 Datei, aus welcher die Trainingsdaten stammen, referenziert werden. Dann werden die Parameter \texttt{validation{\_}data{\_}path} sowie \texttt{test{\_}data} ignoriert. Ausserdem muss der Parameter \texttt{samples{\_}per{\_}epoch} gesetzt werden.\\
			\texttt{randomize{\_}test{\_}data} & \texttt{true} & Wenn diser Parameter auf \texttt{true} gesetzt wird, werden die geladenen Trainingsdaten zufällig durchmischt.\\
			\texttt{use{\_}random{\_}embeddings} & \texttt{false} & Falls dieser Parameter auf \texttt{true} gesetzt wird werden die Word-Embeddings zufällig initialisiert.\\
			\texttt{set{\_}class{\_}weights} & \texttt{false} & Entscheidet ob während des Trainings Klassengewichte verwendet werden sollen.\\
			\texttt{samples{\_}per{\_}epoch} & \texttt{0} & Falls die Parameter t\texttt{use{\_}preprocessed{\_}data} und \texttt{preprocessed{\_}data} gesetzt sind, muss hier angegeben werden wieviel Datensätze aus den vorverarbeiteten Daten verwendet werden sollen.\\
			\texttt{test{\_}data} & \texttt{null} & Über diesen Parameter kann konfiguriert werden, welche Trainingsdaten verwendet werden sollen. Dabei muss entweder der Pfad zu einer TSV Datei angegeben werden, oder ein Objekt welches als Schlüssel die Pfade zu den zu ladenden TSV Dateien und als Werte die zu ladenden Anzahl Datensätze enthält. Wird ignoriert wenn vorverarbeitete Daten verwendet werden.\\
			\texttt{use{\_}preprocessed{\_}data} & \texttt{false} & Muss auf \texttt{true} gesetzt werden falls der Parameter \texttt{preprocessed{\_}data} gesetzt wurde.\\
			\texttt{validation{\_}data{\_}path} & \texttt{null} & Über diesen Parameter wird konfiguriert, welche Daten für die Validierung während und am Ende des Trainings verwendet werden sollen. Der Aufbau ist dabei derselbe wie beim Parameter \texttt{test{\_}data}. Wird ignoriert wenn vorverarbeitete Daten verwendet werden.\\
			\texttt{validation{\_}split} & \texttt{0.0} & Dieser Parameter gibt an, welcher Bruchteil der Trainingsdaten als Validierungsdaten verwendet werden sollen. Falls der Parameter \texttt{validation{\_}data{\_}path} gesetzt ist wird dieser Parameter ignoriert.\\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption{Explanation of the important configuration parameters of the software system (part 1).}
\end{table}

The descriptions above are neither complete nor concluding. We recommend consult the source code for the exact behavior of the additional parameters

\clearpage

An example configuration (here from the OpenSubtitles experiment) can look as follows:

\begin{figure}[thp]
	\centering
	\begin{tabular}{c}  % the tabular makes the listing as small as possible and centers it
		\begin{lstlisting}[style=json]
		{
			"epochs": 150000,
			"batches_per_epoch": 100,
			"batches_per_validation": 2500,
			"epochs_per_validation": 50,
			"save_model_after_n_epochs": 100,
			"batch_size": 64,
			"cell_type": "LSTM",
			"num_hidden_units": 2048,
			"hidden_state_reduction_size": 1024,
			"num_encoder_layers": 1,
			"num_decoder_layers": 0,
			"training_data": "data/opensubtitles-2016-new/opensubtitles_2016.train.0.txt",
			"validation_data": "data/opensubtitles-2016-new/opensubtitles_2016.valid.0.txt",
			"vocabulary": "data/opensubtitles-2016-new/vocab_opensubtitles_2016_50k.pickle",
			"max_random_embeddings_size": 1024,
			"max_input_length": 30,
			"max_output_length": 30,
			"reverse_input": false,
			"show_predictions_while_training": true,
			"buckets": [[30, 30]],
			"sampled_softmax_number_of_samples": 512,
			"word_tokenizer": "none",
			"use_last_output_as_input": true,
			"start_training_from_beginning": false
		}
		\end{lstlisting}
	\end{tabular}
	\label{software_usage:config_json_example}
	\caption{Example JSON configuration for the OpenSubtitles experiment.}
\end{figure}

To start experiments, one has to invoke the \texttt{run.sh} script at the root of the repository with the configuration of the experiment desired to run.

\begin{lstlisting}[frame=none]
$ ./run.sh configs/config-1.json
\end{lstlisting}

The results are then stored in a directory in \texttt{results/} within a subdirectory named after the name of the configuration file supplied to \texttt{run.sh}.

\section{Web Frontend}
We implemented a simple web frontend for communicating with already trained models. It is implemented by using \texttt{flask}, \texttt{jQuery} and the \texttt{bootstrap} frontend framework. To us the frontende, one has to start  it using the following command:

\begin{lstlisting}[frame=none]
$ python scripts/web/app.py
\end{lstlisting}

This will start the web frontend running on \texttt{localhost} and using the port 9001. After it has been started, one has to select the model it would like to load from the models in the dropdown at the top. All models found in the \texttt{results/} directory are listed there. After the selection, a session has to be started by clicking on the \emph{Start} button. This might take a moment, as the loading of the model is a costly process. After the model has been loaded (as indicated by ...), one can start to communicate with it by sending text. Keep in mind, that the kind of output of the model (e.g. beam-search or greedy) directly depends on the configuration stored in the directory where the loaded model is located. This means, if one wants to see for example the output of all beams (in case of beam-search), one has to change the configuration value of the key \texttt{beam\_search\_only\_best} to \texttt{true} there. For a comprehensive list of all configuration values and their meaning, please see Chapter~\ref{sofware_usage:config}.

!!IMAGE!!

Mithilfe der bereitgestellten Weboberfläche können durchgeführte Experimente analysiert werden. Um dies zu ermöglichen sind drei Kernfunktionalitäten implementiert: Es wird eine Übersicht über alle JSON Dateien im entsprechenden Resultat-Ordner angezeigt, Metriken können mittels \texttt{math.js}\footnote{http://mathjs.org/} ausgewertet und es ist möglich Plots über Metriken mittels \texttt{matplotlib}\footnote{http://matplotlib.org/} zu erstellen.

Die Weboberfläche selbst kann über den Befehl \texttt{python web/app.py} gestartet werden. Diese ist dann über den Browser mittels der URL \texttt{http://localhost:5000} erreichbar.