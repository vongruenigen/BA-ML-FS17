\chapter*{Abstract}
In the following thesis we investigate the construction of an end-to-end conversational dialog system based on recurrent neural networks and sequence-to-sequence learning. We use an already existing system as the reference architecture. 

The main goal of the research is to investigate if a downsized model, trained on a single GPU, still exhibits a comparable performance compared to larger systems.

The first Chapters are dedicated to the development of the software system and the datasets and methods used to conduct the experiments.

The analysis of the resulting models is done under several aspects. First, we look into the learning process. We show that the structure and linguistic nature of different datasets has a clear impact on the learning process of such models. Evaluations to asses the performance follow, including tests with a newly proposed metric based on the Sent2Vec library for measuring semantic similarity.

Our previous analysis revealed several problems our models exhibited. One of the main issues is that such models tend to generate generic responses which lead to deteriorating results. This does not match with our subjective impression that the model indeed becomes better over time. To find an explanation for this behavior we investigate how the language, used by the the models, evolves over time. This analysis shows that language variety increases with training time and the occurrence of generic responses decreases.

A comparison with two other systems, namely CleverBot and the results from a paper by Vinyals and Le on ``Neural Conversational Model''~\cite{Vinyals:2015}, follow subsequently. This comparison shows that our models can deliver models that have performance comparable to other systems, as long as the dialogs have limited complexit. We believe that reasons for the comparatively worse performance of our models include smaller model size, as well as shorter training time.

Although the results do not match our expectations, we are satisfied with the work. The models can, at least sometimes, generate meaningful dialogs, such as the response ``i m a bot'' to the question ``What are you?''.

\chapter*{Zusammenfassung}
In der folgenden Arbeit untersuchen wir den Aufbau eines End-To-End Dialogsystems mit Hilfe von Recurrent Neural Networks und der Sequence-To-Sequence Lernmethode.

Das Ziel dieser Arbeit ist es, herauszufinden ob ein kleineres Modell, welches auf einer GPU trainiert wurde, noch vergleichbar gute Ergebnisse wie ein grösseres hervorbringen kann.

Die ersten Kapitel beschreiben die Entwicklung des Softwaresystems, die Datensätze sowie Methodik zur Durchführung der Experimente.

Die Analyse der daraus resultierenden Modelle erfolgt unter mehreren Aspekten. Als Erstes analysieren wir den Lernprozess. Dabei hat sich gezeigt, dass die Struktur und der sprachliche Ursprung der Daten einen spürbaren Einfluss auf den Lernprozess der Modelle hat. Anschliessend evaluieren wir die Leistung unserer Modelle, unter anderem mit einer neu vogeschlagenen Metrik basierend auf der Sent2Vec Bibliothek, um die semantische Ähnlichkeit numerisch zu messen.

Die Analysen zeigen, dass unsere Modelle einige Schwierigkeiten haben. Ein grosses Problem ist, dass solche Modelle dazu tendieren, generische Antworten zu erzeugen, was zu einer Verschlechterung der Ergebnisse führt. Dies stimmt aber nicht mit unserem subjektiven Eindruck überein, dass die Modelle mit der Zeit besser werden. Um dieses Verhalten erklären zu können, untersuchen wir, wie sich die von den Modellen verwendete Sprache im Laufe der Zeit entwickelt. Diese Analyse zeigt auf, dass die Sprachvielfalt mit fortlaufendem Training grösser wird und der Anteil generischen Antworten sinkt.

Anschliessend folgt ein Vergleich mit anderen Systemen, nämlich mit Cleverbot und den Ergebnissen aus dem Paper ``Neural Conversational Model'' von Vinyals and Le~\cite{Vinyals:2015}. Dabei zeigt sich, dass unsere Modelle vergleichbar gute Ergebnisse wie die anderen Systeme erbringen, sofern die Dialoge nicht zu komplex werden. Die Ursachen für die teilweise schlechteren Ergebnisse unserer Modelle im Vergleich mit den anderen Systemen vermuten wir in der Grösse der Modelle und der kurzen Trainingszeit.

Obwohl die Ergebnisse nicht ganz unseren Erwartungen entsprachen, sind wir insgesamt zufrieden. Unsere Modelle sind in der Lage, teilweise sinnvolle und interessante Antworten zu erzeugen, wie zum Beispiel ``i m a bot'' als Antwort auf die Frage ``What are you?''.