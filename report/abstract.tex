\chapter*{Abstract}
In the following thesis we are investigating into construction of an end-to-end conversational dialog system based on recurrent neural networks and sequence-to-sequence learning. We use an already existing system as the reference architecture. 

The main topic of the research is to investigate if a downsized model, trained on a single GPU, still exhibits a comparable performance compared to the larger system. \todo{umgeschrieben, bitte kurz prüfen.}

The first chapters are dedicated to the development of the software system and the datasets and methods used to conduct the experiments.

The analysis of the resulting models is done under several aspects. First, we are going to look into the learning process. It is shown that the structure and linguistic nature of different datasets has a clear impact on the learning process of such models. Evaluations to asses the performance follow afterwards, which includes tests with a newly proposed metric based on the Sent2Vec library for measuring semantic similarity.

The previous analysis revealed several problems our models exhibited. One of the main issues is that such models tend to generate generic responses which leads to deteriorating results. This does not match with our subjective impression that the model indeed become better over time. To find an explanation for this behaviour we investigate how the language, used by the the models, evolves over time. This analysis shows that language variety increases with training time and the occurrence of generic responses decreases.

A comparison with two other systems, namely the CleverBot and the results from the ``Neural Conversational Model'' paper, follow subsequently. This comparison shows that our models can deliver comparable results as other models, as long as the dialogs have limited complexity. The assumed reasons for the inferior results from our models are the smaller model size as well as the shorter training time, compared to other systems.

Although the results do not match our expectations, we are satisfied with the work. The system is able to, at least partially, generate meaningful dialogs, such as the response ``i m a bot'' to the question ``what are you ?''.

\chapter*{Zusammenfassung}
In der folgenden Arbeit untersuchen wir den Aufbau eines en-to-end Dialogsystems mit Hilfe rekurrenter neuronaler Netze und der sequence-to-sequence Lernmethode.\todo{rekurrent, tönt komisch, google meint aber das heisst so}

Das Kernthema dieser Arbeit ist herauszufinden, ob ein kleineres Modell, welches auf einer GPU trainiert wurde, noch vergleichbar gute Ergebnisse wie ein Grösseres hervorbringen kann.

Die ersten Kapitel beschreiben die Entwicklung des Softwaresystems, der Datensätze und Methoden zur Durchführung der Experimente.

Die Analyse der daraus resultierenden Modelle erfolgt unter mehreren Aspekten. Als Erstes analysieren wir den Lernprozess. Dabei hat sich gezeigt, dass die Struktur und der sprachliche Ursprung der Daten einen spürbaren Einfluss auf den Lernfortschritt der Modelle hat. Anschliessend evaluierten wir die Performanz unseren Modell, unter anderem mit der gerade erschienenen Metrik Sent2vec Library, um die semantische Ähnlichkeit numerisch zu testen.

Die Analysen zeigten, dass unsere Modelle einige Schwierigkeiten hatte. Ein grosses Problem ist, dass solche Modelle zu generischen Antworten tendieren, welche zu einer Verschlechterung der Ergebnisse führt. Dies stimmt aber nicht mit unserem subjektiv Eindruck überein, dass die Modelle mit der Zeit besser werden. Um dieses Verhalten erklären zu können, untersuchten wir, wie sich die von den Modellen verwendete Sprach, im Laufe der Zeit entwickelt. Diese Analyse zeigte auf, dass die Sprachvielfalt mit fortlaufendem Training grösser wird und der Anteil generischen Antworten sinkt.

Anschliessend folgte ein Vergleich mit anderen Systemen, konkret mit Cleverbot und den Ergebnisse aus dem ``Neural Conversational Model'' Paper. Dabei zeigte sich, dass unser Modell vergleichbare Ergebnisse wie die anderen Modelle erbringt, sofern die Dialoge nicht komplex sind. Die Ursachen für die teilweise schlechteren Ergebnisse unserer Modelle im Vergleich mit den anderen Systemen vermuten wir in der grösse des Modells und der kürzeren Trainingszeit.

Obwohl die Ergebnisse nicht ganz unseren Erwartungen entsprachen, sind wir insgesamt zufrieden. Unser System ist in der Lage, teilweise sinnvolle Dialoge zu erzeugen, wie zum Beispiel die Antwort  `` i m a bot '' auf die Frage "What are you ?". \todo{wollen wir hier wieder von system reden? wäre schliessend zum Anfang wo wir von einem Dialogsystem reden.}