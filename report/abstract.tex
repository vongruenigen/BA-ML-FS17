\chapter*{Abstract}
In the following thesis investigating into construction of an end-to-end conversational dialog system based on recurrent neural networks and sequence-to-sequence learning. We use an already existing system as the reference architecture. 

The main topic of the research is to investigate if a downsized model still exhibits a comparable performance if trained on a single GPU, compared to the larger system trained on a larger, CPU based platform.

The first chapters are dedicated to the development of the software system and the datasets and methods used to conduct the experiments.

The analysis of the resulting models is focussing on different aspects. First, we investigtate into the learning process with the intention to identify differences when using two different datasets for the training. We show that the structure and linguistic nature of different datasets has a identifiable impact on the learning process of such models. Different evaluations to asses their performance follow afterwards. This includes tests with a newly proposed metric based on the Sent2Vec library.

The previous analysis revealed several problems our models exhibited. One of the main issues is that such models tend to generate generic responses which leads to deteriorating results. This does not match with our subjective impression that the model indeed become better over time. To find an explanation for this behaviour we investigate how the language, used by the the models, evolves over time. This analysis shows that language variety increases with training time and the occurrence of generic responses decreases. We also show that it is not recommended to use small datasets for multiple epochs of the training without also applying regularization methods.

A comparison with two other systems, namely the CleverBot and the results from the ``Neural Conversational Model'' paper, follow subsequently. This comparison shows that our models can deliver comparable results as other models, as long as the dialogs have limited complexity. The assumed reasons for the inferior results from our models are the smaller model size as well as the shorter training time, compared to other models.

In the last part, we conduct an analysis of several technical specifics. This includes short analyzes of using a beam-search decoder, the assistance the soft-attention mechanism provides to the models and the clustering of thought vectors. 

Although the results do not match our expectations, we are satisfied with the work. The system is able to, at least partially, generate meaningful dialogs, such as the response ``i m a bot'' to the question ``what are you ?''.
