\chapter*{Abstract}
In the following thesis we are investigating into construction of an end-to-end conversational dialog system based on recurrent neural networks and sequence-to-sequence learning. We use an already existing system as the reference architecture. 

The main topic of the research is to investigate if a downsized model, trained on a single GPU, still exhibits a comparable performance compared to larger systems.

The first Chapters are dedicated to the development of the software system and the datasets and methods used to conduct the experiments.

The analysis of the resulting models is done under several aspects. First, we are going to look into the learning process. It is shown that the structure and linguistic nature of different datasets has a clear impact on the learning process of such models. Evaluations to asses the performance follow afterwards, which includes tests with a newly proposed metric based on the Sent2Vec library for measuring semantic similarity.

The previous analysis revealed several problems our models exhibited. One of the main issues is that such models tend to generate generic responses which leads to deteriorating results. This does not match with our subjective impression that the model indeed become better over time. To find an explanation for this behavior we investigate how the language, used by the the models, evolves over time. This analysis shows that language variety increases with training time and the occurrence of generic responses decreases.

A comparison with two other systems, namely the CleverBot and the results from the ``Neural Conversational Model'' paper, follow subsequently. This comparison shows that our models can deliver comparable results as other models, as long as the dialogs have limited complexity. The assumed reasons for the inferior results from our models are the smaller model size as well as the shorter training time, compared to other systems.

Although the results do not match our expectations, we are satisfied with the work. The models are able to, at least partially, generate meaningful dialogs, such as the response ``i m a bot'' to the question ``what are you ?''.

\chapter*{Zusammenfassung}
In der folgenden Arbeit untersuchen wir den Aufbau eines End-To-End Dialogsystems mit Hilfe Recurrent Neural Networks und der Sequence-To-Sequence Lernmethode.

Das Kernthema dieser Arbeit ist herauszufinden, ob ein kleineres Modell, welches auf einer GPU trainiert wurde, noch vergleichbar gute Ergebnisse wie ein Grösseres hervorbringen kann.

Die ersten Kapitel beschreiben die Entwicklung des Softwaresystems, die Datensätze sowie Methodik zur Durchführung der Experimente.

Die Analyse der daraus resultierenden Modelle erfolgt unter mehreren Aspekten. Als Erstes analysieren wir den Lernprozess. Dabei hat sich gezeigt, dass die Struktur und der sprachliche Ursprung der Daten einen spürbaren Einfluss auf den Lernprozess der Modelle hat. Anschliessend evaluieren wir die Performanz unserer Modelle, unter anderem mit einer neu vogeschlagenen Metrik basierend auf der Sent2Vec Bibliothek, um die semantische Ähnlichkeit numerisch zu messen.

Die Analysen zeigten, dass unsere Modelle einige Schwierigkeiten hatten. Ein grosses Problem ist, dass solche Modelle dazu tendieren, generische Antworten zu generieren, was zu einer Verschlechterung der Ergebnisse führt. Dies stimmt aber nicht mit unserem subjektiven Eindruck überein, dass die Modelle mit der Zeit besser werden. Um dieses Verhalten erklären zu können, untersuchen wir, wie sich die von den Modellen verwendete Sprache im Laufe der Zeit entwickelt. Diese Analyse zeigt auf, dass die Sprachvielfalt mit fortlaufendem Training grösser wird und der Anteil generischen Antworten sinkt.

Anschliessend folgte ein Vergleich mit anderen Systemen, konkret mit Cleverbot und den Ergebnisse aus dem Paper ``Neural Conversational Model''. Dabei zeigte sich, dass unsere Modelle vergleichbar gute Ergebnisse wie die anderen Systeme erbringen, sofern die Dialoge nicht zu komplex werden. Die Ursachen für die teilweise schlechteren Ergebnisse unserer Modelle im Vergleich mit den anderen Systemen vermuten wir in der Grösse der Modelle und der kurzen Trainingszeit.

Obwohl die Ergebnisse nicht ganz unseren Erwartungen entsprachen, sind wir insgesamt zufrieden. Unsere Modelle sind in der Lage, teilweise sinnvolle und interessante Antworten zu erzeugen, wie zum Beispiel ``i m a bot'' als Antwort auf die Frage ``what are you ?''.